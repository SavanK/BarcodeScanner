{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(id, filename, filepath, bbox, label):\n",
    "    img_raw = open(filepath, \"rb\").read()\n",
    "    key = hashlib.sha256(img_raw).hexdigest()\n",
    "    width, height = PIL.Image.open(filepath).size\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        \"image/height\": tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        \"image/width\": tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        \"image/filename\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode(\"utf-8\")])),\n",
    "        \"image/source_id\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(id).encode(\"utf-8\")])),\n",
    "        \"image/key/sha256\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode(\"utf-8\")])),\n",
    "        \"image/encoded\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "        \"image/format\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"jpg\".encode(\"utf8\")])),\n",
    "        \"image/object/bbox/xmin\": tf.train.Feature(float_list=tf.train.FloatList(value=[int(bbox[0]) / width])),\n",
    "        \"image/object/bbox/xmax\": tf.train.Feature(float_list=tf.train.FloatList(value=[int(bbox[2]) / width])),\n",
    "        \"image/object/bbox/ymin\": tf.train.Feature(float_list=tf.train.FloatList(value=[int(bbox[1]) / height])),\n",
    "        \"image/object/bbox/ymax\": tf.train.Feature(float_list=tf.train.FloatList(value=[int(bbox[3]) / height])),\n",
    "        \"image/object/class/text\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"1d\".encode(\"utf-8\")])),\n",
    "        \"image/object/class/label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "        \"image/object/difficult\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
    "        \"image/object/truncated\": tf.train.Feature(int64_list=tf.train.Int64List(value=[0])),\n",
    "        \"image/object/view\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[\"Unspecified\".encode(\"utf-8\")])),\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "\n",
    "def create_tfrecord(annotations, dataset_dir, output_path, samples_per_file):    \n",
    "    print(f\"creating tf records at {output_path}\")\n",
    "\n",
    "    # write examples into tfrecord\n",
    "    fid = 0\n",
    "    partition_path = output_path + f\"-{fid:02d}\"\n",
    "    tfwriter = tf.io.TFRecordWriter(partition_path)\n",
    "    for i, annotation in annotations.iterrows():\n",
    "        if (i + 1) % samples_per_file == 0:\n",
    "            fid += 1\n",
    "            partition_path = output_path + f\"-{fid:02d}\"\n",
    "            tfwriter.close()\n",
    "            tfwriter = tf.io.TFRecordWriter(partition_path)\n",
    "\n",
    "        print(f'annotation: {annotation}')\n",
    "        filename = annotation['file']\n",
    "        filepath = os.path.join(dataset_dir, filename)\n",
    "        label = annotation['barcode_type']\n",
    "        bbox_str = annotation['bounding_box']\n",
    "        if bbox_str.startswith('[') and bbox_str.endswith(']'):\n",
    "            bbox_str = bbox_str[1:-1]\n",
    "        bbox = bbox_str.split(',')\n",
    "        \n",
    "        example = create_example(i + 1, filename, filepath, bbox, label)\n",
    "        tfwriter.write(example.SerializeToString())\n",
    "        \n",
    "    tfwriter.close()    \n",
    "\n",
    "\n",
    "def create_train_val_tfrecords(dataset_dir, annotations_file, output_dir, samples_per_file):\n",
    "    print(f'creating train and validation tf records from {annotations_file} at {output_dir}')\n",
    "\n",
    "    # create the output directory if not exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(os.path.basename(os.path.dirname(output_dir)))\n",
    "    \n",
    "    # read annotations\n",
    "    annotations = pd.read_csv(annotations_file)\n",
    "    \n",
    "    # split into train and validation sets\n",
    "    train, val = train_test_split(annotations, test_size=0.2, random_state=42, shuffle=True)\n",
    "    print(f'train size: {train.shape[0]} validation size: {val.shape[0]}')\n",
    "    \n",
    "    # create tfrecords for train and validation set\n",
    "    create_tfrecord(train, dataset_dir, os.path.join(output_dir, \"train.tfrecord\"), samples_per_file)\n",
    "    create_tfrecord(val, dataset_dir, os.path.join(output_dir, \"val.tfrecord\"), samples_per_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = os.path.join(os.getcwd(), 'tfrecords/')\n",
    "DATASET_DIR = os.path.join(os.getcwd(), 'Muenster_Barcode_Database/N95-2592x1944_scaledTo640x480bilinear')\n",
    "ANNOTATIONS_PATH = os.path.join(os.getcwd(), 'Muenster_Barcode_Database/annotations.csv')\n",
    "\n",
    "create_train_val_tfrecords(DATASET_DIR, ANNOTATIONS_PATH, TFRECORDS_DIR, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
